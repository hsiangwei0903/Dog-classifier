{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEF-final.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate a model using the semantically enhanced feature method.\n",
        "The model uses a ResNet backbone.\n",
        "\n",
        "\n",
        "The training dataset is a subset of Stanford Dogs that corresponds with the 25 breeds we were able to collect with the Wyze Cam. The folder `train` is the training data and `wyze`, `yt` and `google` are the testing datasets. The data is available at https://drive.google.com/drive/folders/1GbegJxFDZHp0NiN0bq9VngtMXo9Vjaoi?usp=sharing\n",
        "\n",
        "You will need to modify the paths in the code below."
      ],
      "metadata": {
        "id": "DX3_FRIrH3LT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXMfmopt0ApW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Capstone/SEF-master/"
      ],
      "metadata": {
        "id": "P734D3VL0IwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "IhCUNaqV0I7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import statistics\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "# from .utils import load_state_dict_from_url\n",
        "import pdb\n",
        "import torch.nn.functional as torchf\n",
        "# from utils.misc import SoftSigmoid\n",
        "import pickle as pk\n",
        "import uuid\n",
        "import argparse\n",
        "import torch.optim as opt\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.multiprocessing as mlp\n",
        "import torch.utils.tensorboard as tb\n",
        "import copy\n",
        "import time"
      ],
      "metadata": {
        "id": "fIKo9jki0JI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "qcou_tUh4BU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "id": "60Tg6ERW4pr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ntmQis1o0JZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() > 0 else \"cpu\")\n",
        "device_name = device.type+':'+str(device.index) if device.type=='cuda' else 'cpu'"
      ],
      "metadata": {
        "id": "Gp4ZjnCU0JmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progpath = '/content/drive/MyDrive/Capstone/SEF-master'\n",
        "sys.path.append(progpath)\n",
        "\n",
        "datasetname = 'stdogs25'\n",
        "image_size = 448\n",
        "batchsize = 16\n",
        "nthreads = 4\n",
        "lr = 0.001\n",
        "lmgm = 1\n",
        "entropy = 1\n",
        "soft = 0.05\n",
        "epochs = 50\n",
        "optmeth = 'sgd'\n",
        "regmeth = 'cms'\n",
        "\n",
        "\n",
        "# Number of attentions for different datasets\n",
        "# nparts = 2 recommended for Stanford Dogs\n",
        "nparts = 2\n",
        "\n",
        "\n",
        "# 'resnet50attention' for SEF, 'resnet50maxent' for ResNet with MaxEnt, 'resnet50vanilla' for the vanilla ResNet\n",
        "networkname = 'resnet18attention'\n",
        "if networkname.find('attention') > -1:  # SEF based on ResNet\n",
        "    attention_flag = True\n",
        "    maxent_flag = False\n",
        "else:                                   # The vanilla ResNet\n",
        "    lmgm=entropy=soft=0\n",
        "    nparts=1\n",
        "    attention_flag = False\n",
        "    maxent_flag = False\n",
        "\n",
        "\n",
        "# Displaying logs\n",
        "timeflag = time.strftime(\"%d-%b-%Y-%H:%M\")\n",
        "# writer = tb.SummaryWriter(log_dir='./runs/'+datasetname+'/'+networkname+time.strftime(\"%d-%b-%Y\"))\n",
        "log_items = r'{}-net{}-att{}-lmgm{}-entropy{}-soft{}-lr{}-imgsz{}-bsz{}'.format(\n",
        "    datasetname, int(networkname[6:8]), nparts, lmgm, entropy, soft, lr, image_size, batchsize)\n",
        "writer = tb.SummaryWriter(comment='-'+log_items)\n",
        "logfile = open('./runs/'+log_items+'.txt', 'w')\n",
        "\n",
        "\n",
        "###### MODEL NAME ######\n",
        "modelname = log_items + f'-{epochs}epoch' + '.model'\n",
        "# modelname = log_items + f'-{epochs}epoch' + '-aug5' + '.model'\n",
        "# modelname = log_items + '-aug' + '.model'\n",
        "\n",
        "\n",
        "# Model zoo and dataset path\n",
        "datapath = '/content/drive/MyDrive/Capstone/' # path to dataset\n",
        "modelzoopath = '/content/drive/MyDrive/Capstone/SEF-master/' # path to SEF master folder\n",
        "sys.path.append(modelzoopath)\n",
        "datasetpath = '/content/drive/MyDrive/Capstone/stdogs25'\n",
        "modelpath = '/content/drive/MyDrive/Capstone/SEF-master/models'\n",
        "resultpath = '/content/drive/MyDrive/Capstone/SEF-master/runs'"
      ],
      "metadata": {
        "id": "Y8XR2w6s0J1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms for different subsets of stdogs25\n",
        "# wyze, google and yt are our test sets\n",
        "data_transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((600,600)),\n",
        "        transforms.RandomCrop((448, 448)),\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])          \n",
        "    ]),\n",
        "    'wyze': transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'yt': transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'google': transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "kLaO7Og30KC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################################\n",
        "###### Select the test set for training, can reselect for evaluation later ######\n",
        "#################################################################################\n",
        "testset = 'wyze'\n",
        "# testset = 'google'\n",
        "# testset = 'yt'\n",
        "\n",
        "# ORIGINAL \n",
        "# Organizing datasets\n",
        "datasplits = {x: datasets.ImageFolder(os.path.join(datasetpath, x), data_transform[x])\n",
        "              for x in ['train', testset]}\n",
        "\n",
        "# Preparing dataloaders for datasets\n",
        "dataloader = {x: torch.utils.data.DataLoader(datasplits[x], batch_size=batchsize, shuffle=True, num_workers=nthreads)\n",
        "              for x in ['train', testset]}\n",
        "\n",
        "class_names = datasplits['train'].classes\n",
        "num_classes = len(class_names)\n",
        "print(len(dataloader))"
      ],
      "metadata": {
        "id": "vy7ztu6t0fll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eps = torch.finfo().eps\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "# Download the .pth file for the model you are going to be training and place in the SEF master folder\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "mlPniYw10kac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model architecture"
      ],
      "metadata": {
        "id": "LrQqSd2LL2v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalMaxGlobalMin(nn.Module):\n",
        "\n",
        "    def __init__(self, rho, nchannels, nparts=1, device='cpu'):\n",
        "        super(LocalMaxGlobalMin, self).__init__()\n",
        "        self.nparts = nparts\n",
        "        self.device = device\n",
        "        self.nchannels = nchannels\n",
        "        self.rho = rho      \n",
        "\n",
        "        \n",
        "        nlocal_channels_norm = nchannels // self.nparts\n",
        "        reminder = nchannels % self.nparts\n",
        "        nlocal_channels_last = nlocal_channels_norm\n",
        "        if reminder != 0:\n",
        "            nlocal_channels_last = nlocal_channels_norm + reminder\n",
        "        \n",
        "        # seps records the indices partitioning feature channels into separate parts\n",
        "        seps = []\n",
        "        sep_node = 0\n",
        "        for i in range(self.nparts):\n",
        "            if i != self.nparts-1:\n",
        "                sep_node += nlocal_channels_norm                \n",
        "                #seps.append(sep_node)\n",
        "            else:\n",
        "                sep_node += nlocal_channels_last                \n",
        "            seps.append(sep_node)\n",
        "        self.seps = seps\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):  \n",
        "        x = x.pow(2)\n",
        "        intra_x = []\n",
        "        inter_x = []\n",
        "        for i in range(self.nparts):\n",
        "            if i == 0:        \n",
        "                intra_x.append((1 - x[:, :self.seps[i], :self.seps[i]]).mean()) \n",
        "            else:              \n",
        "                intra_x.append((1 - x[:, self.seps[i-1]:self.seps[i], self.seps[i-1]:self.seps[i]]).mean())\n",
        "                inter_x.append(x[:, self.seps[i-1]:self.seps[i], :self.seps[i-1]].mean())\n",
        "        \n",
        "        loss = self.rho * 0.5 * (sum(intra_x) / self.nparts + sum(inter_x) / (self.nparts*(self.nparts-1)/2)) \n",
        "                 \n",
        "\n",
        "        return loss\n",
        "        "
      ],
      "metadata": {
        "id": "QWbHtjSf0kof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "       \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "9KavVyXb0k3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, nparts=0, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None, attention=False, device='cpu'):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.attention = attention\n",
        "        self.device = device\n",
        "        self.nparts = nparts\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        if self.attention:            \n",
        "            nfeatures = 512 * block.expansion            \n",
        "            nlocal_channels_norm = nfeatures // self.nparts\n",
        "            reminder = nfeatures % self.nparts\n",
        "            nlocal_channels_last = nlocal_channels_norm\n",
        "            if reminder != 0:\n",
        "                nlocal_channels_last = nlocal_channels_norm + reminder\n",
        "            fc_list = []\n",
        "            separations = []\n",
        "            sep_node = 0\n",
        "            for i in range(self.nparts):\n",
        "                if i != self.nparts-1:\n",
        "                    sep_node += nlocal_channels_norm\n",
        "                    fc_list.append(nn.Linear(nlocal_channels_norm, num_classes))\n",
        "                    #separations.append(sep_node)\n",
        "                else:\n",
        "                    sep_node += nlocal_channels_last\n",
        "                    fc_list.append(nn.Linear(nlocal_channels_last, num_classes))\n",
        "                separations.append(sep_node)\n",
        "            self.fclocal = nn.Sequential(*fc_list)\n",
        "            self.separations = separations \n",
        "            self.fc = nn.Linear(512*block.expansion, num_classes) \n",
        "\n",
        "        else:            \n",
        "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "  \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x) \n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.attention:\n",
        "\n",
        "            nsamples, nchannels, height, width = x.shape\n",
        "        \n",
        "            xview = x.view(nsamples, nchannels, -1)\n",
        "            xnorm = xview.div(xview.norm(dim=-1, keepdim=True)+eps)\n",
        "            xcosin = torch.bmm(xnorm, xnorm.transpose(-1, -2))                               \n",
        "            \n",
        "\n",
        "            attention_scores = []\n",
        "            for i in range(self.nparts):\n",
        "                if i == 0:\n",
        "                    xx = x[:, :self.separations[i]]\n",
        "                else:\n",
        "                    xx = x[:, self.separations[i-1]:self.separations[i]]\n",
        "                xx_pool = self.avgpool(xx).flatten(1)\n",
        "                attention_scores.append(self.fclocal[i](xx_pool))\n",
        "            xlocal = torch.stack(attention_scores, dim=0)\n",
        "\n",
        "            xmaps = x.clone().detach()\n",
        "            \n",
        "            # for global\n",
        "            xpool = self.avgpool(x)\n",
        "            xpool = torch.flatten(xpool, 1)\n",
        "            xglobal = self.fc(xpool)\n",
        "\n",
        "            \n",
        "            return xglobal, xlocal, xcosin, xmaps\n",
        "        else:\n",
        "            # for original resnet outputs\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "            return x"
      ],
      "metadata": {
        "id": "rGW-0pdA0lFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _resnet(arch, block, layers, pretrained, progress, model_dir=None, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls[arch], model_dir=model_dir))\n",
        "        state_dict = torch.hub.load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, model_dir=None, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, model_dir,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, progress=True, model_dir=None, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, model_dir,\n",
        "                   **kwargs)"
      ],
      "metadata": {
        "id": "24njNaQj0lgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define your model"
      ],
      "metadata": {
        "id": "rNAilAryMAin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(pretrained=False, model_dir=modelzoopath, nparts=nparts, num_classes=num_classes, attention=attention_flag, device=device)\n",
        "state_dict_path = os.path.join(modelzoopath, 'resnet18-5c106cde.pth')\n",
        "\n",
        "state_params = torch.load(state_dict_path)\n",
        "\n",
        "# pop redundant params from laoded states\n",
        "state_params.pop('fc.weight')\n",
        "state_params.pop('fc.bias')\n",
        "\n",
        "# modify output layer\n",
        "in_channels = model.fc.in_features\n",
        "new_fc = nn.Linear(in_channels, num_classes, bias=True)\n",
        "model.fc = new_fc\n",
        "\n",
        "# initializing model using pretrained params except the modified layers\n",
        "model.load_state_dict(state_params, strict=False)\n",
        " \n",
        "\n",
        "# tensorboard writer\n",
        "images, _ = next(iter(dataloader[testset]))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid)\n",
        "writer.add_graph(model, images)\n",
        "\n",
        "# to gpu if available\n",
        "model.to(device)   # model.cuda(device)"
      ],
      "metadata": {
        "id": "Wrm2cVG70ltJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Semantic group loss\n",
        "lmgm_loss = LocalMaxGlobalMin(rho=lmgm, nchannels=512*4, nparts=nparts, device=device)\n",
        "\n",
        "criterion = [cls_loss, lmgm_loss]\n",
        "\n",
        "optimizer = opt.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "# Optimization scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  ## CHANGED STEP_SIZE FROM 20 to 10"
      ],
      "metadata": {
        "id": "CGI7BGbZ0mDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=-1)\n",
        "logsoftmax = nn.LogSoftmax(dim=-1)\n",
        "kldiv = nn.KLDivLoss(reduction='batchmean')"
      ],
      "metadata": {
        "id": "_ygBJUgm0xis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 448, 448))"
      ],
      "metadata": {
        "id": "Mn-MqrLMFY7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train function"
      ],
      "metadata": {
        "id": "IAum2VEOMLZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, scheduler, datasetname=None, isckpt=False, epochs=5, networkname=None, writer=None, maxent_flag=False, device='cpu', **penalty):\n",
        "    \n",
        "    output_log_file = penalty['logfile']\n",
        "    nparts = model.nparts\n",
        "    attention_flag = model.attention\n",
        "    \n",
        "    if isinstance(dataloader, dict):\n",
        "        dataset_sizes = {x: len(dataloader[x].dataset) for x in dataloader.keys()}\n",
        "        print(dataset_sizes)\n",
        "    else:\n",
        "        dataset_size = len(dataloader.dataset)\n",
        "\n",
        "    if not isinstance(criterion, list):\n",
        "        criterion = [criterion]\n",
        "\n",
        "    best_model_params = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    global_step = 0\n",
        "    global_step_resume = 0\n",
        "    best_epoch = 0\n",
        "    best_step = 0\n",
        "    start_epoch = -1\n",
        "    \n",
        "\n",
        "    # if isckpt:\n",
        "    #     checkpoint = modelserial.loadCheckpoint(datasetname+'-'+networkname)\n",
        "\n",
        "    #     # records for the stopping epoch\n",
        "    #     start_epoch = checkpoint['epoch']\n",
        "    #     global_step_resume = checkpoint['global_step']\n",
        "    #     model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    #     # records for the epoch with the best performance\n",
        "    #     best_model_params = checkpoint['best_state_dict']\n",
        "    #     best_acc = checkpoint['best_acc']\n",
        "    #     best_epoch = checkpoint['best_epoch']\n",
        "    #     optimizer.param_groups[0]['lr'] = checkpoint['current_lr']\n",
        "\n",
        "    since = time.time()\n",
        "    for epoch in range(start_epoch+1, epochs):\n",
        "\n",
        "        # print to file\n",
        "        print('Epoch {}/{}'.format(epoch, epochs), file=output_log_file)\n",
        "        print('-' * 10, file=output_log_file)\n",
        "\n",
        "        # print to terminal\n",
        "        print('Epoch {}/{}'.format(epoch, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "\n",
        "        for phase in ['train', testset]:\n",
        "            if phase == 'train':\n",
        "                # scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "                global_step = global_step_resume\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                global_step_resume = global_step\n",
        "\n",
        "            running_cls_loss = 0.0\n",
        "            running_reg_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            running_corrects_parts = [0.0] * nparts\n",
        "            epoch_acc_parts = [0.0] * nparts\n",
        "\n",
        "\n",
        "            for inputs, labels in dataloader[phase]:\n",
        "                inputs = inputs.cuda(device)\n",
        "                labels = labels.cuda(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    if attention_flag:\n",
        "                        # outputs are logits from linear models\n",
        "                        xglobal, xlocal, xcosin, xmaps = model(inputs)\n",
        "                        probs = softmax(xglobal)\n",
        "                        cls_loss = criterion[0](xglobal, labels)\n",
        "\n",
        "                        ############################################################## prediction\n",
        "\n",
        "                        # prediction of every  branch\n",
        "                        probl, predl, logprobl = [], [], []\n",
        "                        for i in range(nparts):\n",
        "                            probl.append(softmax(torch.squeeze(xlocal[i])))\n",
        "                            predl.append(torch.max(probl[i], 1)[-1])\n",
        "                            logprobl.append(logsoftmax(torch.squeeze(xlocal[i])))\n",
        "\n",
        "\n",
        "                        ############################################################### regularization\n",
        "\n",
        "                        logprobs = logsoftmax(xglobal)\n",
        "                        entropy_loss = penalty['entropy_weights'] * torch.mul(probs, logprobs).sum().div(inputs.size(0))\n",
        "                        soft_loss_list = []\n",
        "                        for i in range(nparts):\n",
        "                            soft_loss_list.append(torch.mul(torch.neg(probs), logprobl[i]).sum().div(inputs.size(0)))\n",
        "                        soft_loss = penalty['soft_weights'] * sum(soft_loss_list).div(nparts)\n",
        "\n",
        "                        # regularization loss\n",
        "                        lmgm_reg_loss = criterion[1](xcosin)\n",
        "                        reg_loss = lmgm_reg_loss + entropy_loss + soft_loss\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        probs = softmax(outputs)\n",
        "                        cls_loss = criterion[0](outputs, labels)\n",
        "                        if maxent_flag:\n",
        "                            logprobs = logsoftmax(outputs)\n",
        "                            reg_loss = torch.mul(probs, logprobs).sum().neg().div(inputs.size(0))\n",
        "                        else:\n",
        "                            reg_loss = torch.tensor(0.0)\n",
        "\n",
        " \n",
        "                    _, preds = torch.max(probs, 1)   # the indeices of the largeset value in each row   \n",
        "\n",
        "                    all_loss = cls_loss + reg_loss\n",
        "                    \n",
        "                    if phase == 'train':                       \n",
        "                        all_loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_cls_loss += (cls_loss.item()) * inputs.size(0)\n",
        "                running_reg_loss += (reg_loss.item()) * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                if attention_flag:\n",
        "                    for i in range(nparts):\n",
        "                        running_corrects_parts[i] += torch.sum(predl[i] == labels.data)\n",
        "                    \n",
        "                # log variables\n",
        "                global_step += 1\n",
        "                if global_step % 100 == 1 and writer is not None and phase is 'train':\n",
        "                    batch_loss = cls_loss.item() + reg_loss.item() \n",
        "                    writer.add_scalar('running loss/running_train_loss', batch_loss, global_step)\n",
        "                    writer.add_scalar('running loss/running_cls_loss', cls_loss, global_step) \n",
        "                    if attention_flag:                     \n",
        "                        writer.add_scalar('running loss/running_lmgm_reg_loss', lmgm_reg_loss, global_step)  \n",
        "                        writer.add_scalar('running loss/running_entropy_reg_loss', entropy_loss, global_step)  \n",
        "                        writer.add_scalar('running loss/running_soft_reg_loss', soft_loss, global_step)  \n",
        "                    elif maxent_flag:\n",
        "                        writer.add_scalar('running loss/running_maxent_reg_loss', reg_loss, global_step)  \n",
        "                    for name, param in model.named_parameters():\n",
        "                        writer.add_histogram('params_in_running/'+name, param.data.clone().cpu().numpy(), global_step)     # global_step\n",
        "\n",
        "\n",
        "\n",
        "            ############################################### for each epoch\n",
        "            \n",
        "            # epoch loss and accuracy\n",
        "            epoch_loss = running_cls_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            if attention_flag:\n",
        "                for i in range(nparts):\n",
        "                    epoch_acc_parts[i] = running_corrects_parts[i].double() / dataset_sizes[phase]\n",
        "\n",
        "\n",
        "            # log variables for each epoch\n",
        "            if writer is not None:\n",
        "                if phase is 'train':\n",
        "                    writer.add_scalar('epoch loss/train_epoch_loss', epoch_loss, epoch)        # global_step\n",
        "                    writer.add_scalar('accuracy/train_epoch_acc', epoch_acc, epoch)          # global_step\n",
        "                    if attention_flag:\n",
        "                        for i in range(nparts):\n",
        "                            writer.add_scalar('accuracy/train_acc_part{}_acc'.format(i), epoch_acc_parts[i], epoch) \n",
        "                    for name, param in model.named_parameters():\n",
        "                        writer.add_histogram('params_in_epoch/'+name, param.data.clone().cpu().numpy(), epoch)     # global_step\n",
        "                elif phase is testset:\n",
        "                    writer.add_scalar('epoch loss/eval_epoch_loss', epoch_loss, epoch)         # global_step_resume\n",
        "                    writer.add_scalar('accuracy/eval_epoch_acc', epoch_acc, epoch)          # global_step_resume\n",
        "                    if attention_flag:\n",
        "                        for i in range(nparts):\n",
        "                            writer.add_scalar('accuracy/eval_acc_part{}_acc'.format(i), epoch_acc_parts[i], epoch) \n",
        "\n",
        "            # print to log file\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), file=output_log_file)\n",
        "            if phase == 'train': print('current lr: {}'.format(optimizer.param_groups[0]['lr']), file=output_log_file)\n",
        "            if phase == testset: print('\\n', file=output_log_file)\n",
        "\n",
        "            # print to terminal\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'train': print('current lr: {}'.format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == testset and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_epoch = epoch\n",
        "                best_step = global_step_resume\n",
        "                best_model_params = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # if phase == 'wyze' and epoch % 5 == 1:\n",
        "            #     modelserial.saveCheckpoint({'epoch': epoch,\n",
        "            #                                 'global_step': global_step,\n",
        "            #                                 'state_dict': model.state_dict(),\n",
        "            #                                 'best_epoch': best_epoch,\n",
        "            #                                 'best_state_dict': best_model_params,\n",
        "            #                                 'best_acc': best_acc, \n",
        "            #                                 'current_lr': optimizer.param_groups[0]['lr']},datasetname+'-'+networkname)\n",
        "        \n",
        "        # adjust learning rate after each epoch\n",
        "        scheduler.step()\n",
        "\n",
        "        \n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed%60), file=output_log_file)\n",
        "    print('Best test Acc: {:4f}'.format(best_acc) , file=output_log_file)\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed%60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "    # recording training params\n",
        "    rsltparams = dict()\n",
        "    rsltparams['datasetname'] = datasetname\n",
        "    rsltparams['nparts'] = model.nparts\n",
        "    rsltparams['val_acc'] = best_acc.item()\n",
        "    rsltparams['lmgm'] = criterion[1].rho\n",
        "    rsltparams['lr'] = optimizer.param_groups[0]['lr']\n",
        "    rsltparams['best_epoch'] = best_epoch\n",
        "    rsltparams['best_step'] = best_step\n",
        "    rsltparams['soft_weights'] = penalty['soft_weights']\n",
        "    rsltparams['entropy_weights'] = penalty['entropy_weights']\n",
        "    # rsltparams['attmaps'] = attmaps\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_params)\n",
        "    return model, rsltparams"
      ],
      "metadata": {
        "id": "utGB88Q406hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start training a model"
      ],
      "metadata": {
        "id": "POWsdZT1MRgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "isckpt = False  # set True to load learned models from checkpoint, defatult False\n",
        "\n",
        "indfile = \"{}: opt={}, lr={}, lmgm={}, nparts={}, entropy={}, soft={}, epochs={}, imgsz={}, batch_sz={}\".format(\n",
        "    datasetname, optmeth, lr, lmgm, nparts, entropy, soft, epochs, image_size, batchsize)\n",
        "print(\"\\n{}\\n\".format(indfile))\n",
        "print(\"\\n{}\\n\".format(indfile), file=logfile)\n",
        "\n",
        "\n",
        "model, train_rsltparams = train(\n",
        "    model, dataloader, criterion, optimizer, scheduler, \n",
        "    datasetname=datasetname, isckpt=isckpt, epochs=epochs, \n",
        "    networkname=networkname, writer=writer, device=device, maxent_flag=maxent_flag,\n",
        "    soft_weights=soft, entropy_weights=entropy, logfile=logfile)\n",
        "\n",
        "\n",
        "train_rsltparams['imgsz'] = image_size\n",
        "train_rsltparams['epochs'] = epochs\n",
        "train_rsltparams['init_lr'] = lr\n",
        "train_rsltparams['batch_sz'] = batchsize\n",
        "\n",
        "print('\\nBest epoch: {}'.format(train_rsltparams['best_epoch']))\n",
        "print('\\nBest epoch: {}'.format(train_rsltparams['best_epoch']), file=logfile)\n",
        "print(\"\\n{}\\n\".format(indfile))\n",
        "print(\"\\n{}\\n\".format(indfile), file=logfile)\n",
        "print('\\nWorking on cluster: {}\\n'.format(device_name))\n",
        "\n",
        "logfile.close()"
      ],
      "metadata": {
        "id": "to8Sg9sw0-ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "PvIU7ZTfMVxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({'model_params':model.state_dict(), 'train_params':train_rsltparams}, os.path.join(modelpath, modelname))"
      ],
      "metadata": {
        "id": "GqMQU18-Y9YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "pbY8Cmcr461w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation function"
      ],
      "metadata": {
        "id": "UxNMukdSMY5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, dataloader=None, device='cpu', datasetname=None):\n",
        "\n",
        "    if not datasetname or datasetname not in ['stdogs', 'wyzedogs', 'wyze', 'yt', 'google', 'stdogs25']:\n",
        "        print(\"illegal dataset\")\n",
        "        return\n",
        "    \n",
        "    attention_flag = model.attention\n",
        "    model.eval()\n",
        "    datasize = len(dataloader.dataset)\n",
        "    running_corrects = 0\n",
        "    good_data = []\n",
        "    bad_data = []\n",
        "    gi = []\n",
        "    bi = []\n",
        "    maps = []\n",
        "    lab = []\n",
        "    inp = []\n",
        "    num_label_counts = dict()\n",
        "    pred_label_counts = dict()\n",
        "    \n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if attention_flag:\n",
        "                outputs, xlocal, xcosin, xmaps = model(inputs)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "\n",
        "        # Save xmaps, inputs and labels in lists\n",
        "        # Return them with result parameters\n",
        "        maps.append(xmaps.cpu().numpy())\n",
        "        lab.append(labels.cpu().numpy())\n",
        "        inp.append(inputs.cpu().numpy())\n",
        "                \n",
        "        probs = softmax(outputs)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # record paths and labels\n",
        "        good_mask = preds == labels.data\n",
        "        bad_mask = torch.logical_not(good_mask)\n",
        "        good_index = good_mask.nonzero()\n",
        "        gi.append(good_index.cpu().numpy())\n",
        "        bad_index = bad_mask.nonzero()\n",
        "        bi.append(bad_index.cpu().numpy())\n",
        "        for idx in good_index:\n",
        "            good_data.append(inputs[idx].cpu().numpy())\n",
        "        for idx in bad_index:\n",
        "            bad_data.append(inputs[idx].cpu().numpy())\n",
        "\n",
        "    \n",
        "    acc = torch.div(running_corrects.double(), datasize).item()\n",
        "    avg_acc = 0.0\n",
        "    print(\"General Accuracy: {}\".format(acc))\n",
        "\n",
        "\n",
        "    rsltparams = dict()\n",
        "    rsltparams['acc'] = acc\n",
        "    rsltparams['avg_acc'] = avg_acc\n",
        "    rsltparams['good_data'] = good_data\n",
        "    rsltparams['bad_data'] = bad_data\n",
        "    rsltparams['good_index'] = gi\n",
        "    rsltparams['bad_index'] = bi\n",
        "    rsltparams['xlocal'] = xlocal\n",
        "    rsltparams['xcosin'] = xcosin\n",
        "    rsltparams['xmaps'] = xmaps\n",
        "    rsltparams['outputs'] = outputs\n",
        "    rsltparams['maps'] = maps\n",
        "    rsltparams['labels'] = lab\n",
        "    rsltparams['inputs'] = inp\n",
        "    \n",
        "    return rsltparams"
      ],
      "metadata": {
        "id": "2lf1u-lA0-V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate a model"
      ],
      "metadata": {
        "id": "qxY5fLAkMgxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Import undistort transform\n",
        "# Must be used before resize transform because it accepts (1920, 1080) Wyze Cam images\n",
        "# Only use undistort on wyze set\n",
        "from undistort import undistort\n",
        "import cv2\n",
        "# from utils.mydataloader import DataLoader\n",
        "\n",
        "eps = torch.finfo().eps\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() > 0 else \"cpu\")\n",
        "progpath = '/content/drive/MyDrive/Capstone/SEF-master'\n",
        "sys.path.append(progpath)\n",
        "datapath = '/content/drive/MyDrive/Capstone/'\n",
        "modelzoopath = '/content/drive/MyDrive/Capstone/SEF-master/models/'\n",
        "sys.path.append(os.path.realpath(modelzoopath))\n",
        "modelpath = os.path.join(progpath, 'models')\n",
        "resultpath = os.path.join(progpath, 'runs')\n",
        "datasetname = 'stdogs25'\n",
        "\n",
        "# modelname = r'stdogs-net50-att1-lmgm0-entropy0-soft0-lr0.01-imgsz448-bsz32.model' # ResNet-50 base model, 120\n",
        "# modelname = r'stdogs-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz32.model' # ResNet-50 with SEF, 120\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz32.model' # ResNet-50 with SEF trained on stdogs25, no augmentation\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz32-aug.model' # ResNet-50 with SEF trained on stdogs25, with augmentation\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-aug.model' # ResNet-50 with SEF trained on stdogs25, with augmentation\n",
        "\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-1epoch.model' # ResNet-50 with SEF trained on stdogs25 for 1 epoch\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-5epoch.model' # ResNet-50 with SEF trained on stdogs25 for 5 epochs\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-10epoch.model' # ResNet-50 with SEF trained on stdogs25 for 10 epochs\n",
        "modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-50epoch.model' # ResNet-50 with SEF trained on stdogs25 for 50 epochs\n",
        "\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-100epoch-aug5.model' # ResNet-50 with SEF trained on stdogs25 for 100 epochs, augmentation x5, lr scheduler 10 steps\n",
        "\n",
        "\n",
        "# modelname = r'stdogs25-net18-att2-lmgm1-entropy1-soft0.05-lr0.001-imgsz448-bsz32-50epoch.model' # ResNet-18 with SEF trained on stdogs25, no aug, 0.001 LR\n",
        "# modelname = r'stdogs25-net18-att1-lmgm0-entropy0-soft0-lr0.001-imgsz448-bsz32-50epoch.model' # ResNet-18 vanilla\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.001-imgsz448-bsz16-50epoch.model'\n",
        "# modelname = r'stdogs25-net50-att1-lmgm0-entropy0-soft0-lr0.001-imgsz448-bsz16-50epoch.model'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "load_params = torch.load(os.path.join(modelpath, modelname), map_location=device)\n",
        "networkname = modelname.split('-')[1]\n",
        "\n",
        "model_state_dict, train_params = load_params['model_params'], load_params['train_params']\n",
        "\n",
        "nparts = train_params['nparts']\n",
        "lmgm = train_params['lmgm']\n",
        "entropy = train_params['entropy_weights']\n",
        "soft = train_params['soft_weights']\n",
        "batchsize = train_params['batch_sz']\n",
        "imgsz = train_params['imgsz']\n",
        "lr = train_params['init_lr']\n",
        "if datasetname == 'stdogs': num_classes = 120\n",
        "if datasetname == 'stdogs25': num_classes = 25\n",
        "attention_flag = True if nparts > 1 else False\n",
        "netframe = 'resnet50' if networkname.find('50') > -1 else 'resnet18'\n",
        "\n",
        "model = resnet50(pretrained=False, model_dir=modelzoopath, nparts=nparts, num_classes=num_classes, attention=attention_flag, device=device)\n",
        "model.load_state_dict(model_state_dict, strict=True)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "datasetpath = os.path.join(datapath, datasetname)\n",
        "datasetpath = os.path.join(datapath, 'stdogs25')\n",
        "\n",
        "# Transforms for test images\n",
        "# Undsistort transform only for testing on wyze images\n",
        "data_transform = {\n",
        "    'wyze': transforms.Compose([\n",
        "        transforms.Lambda(undistort),\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'yt': transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'google': transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# testset = 'wyze'\n",
        "testset = 'google'\n",
        "# testset = 'yt'\n",
        "\n",
        "# Batch size\n",
        "batch_size = 1\n",
        "\n",
        "test_transform = data_transform[testset]\n",
        "\n",
        "testsplit = ImageFolder(os.path.join(datasetpath, testset), data_transform[testset])\n",
        "# Number of images in testset\n",
        "N = len(testsplit)\n",
        "testloader = DataLoader(testsplit, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_rsltparams = eval(model, testloader, datasetname=datasetname, device=device)\n",
        "\n",
        "print('General Acc: {}, Class Avg Acc: {}'.format(test_rsltparams['acc'], test_rsltparams['avg_acc']))"
      ],
      "metadata": {
        "id": "7t936nrh1D8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-1epoch.model'\n",
        "# load_params = torch.load(os.path.join(modelpath, modelname), map_location=device)\n",
        "# networkname = modelname.split('-')[1]\n",
        "# model_state_dict, train_params = load_params['model_params'], load_params['train_params']\n",
        "# model1 = resnet50(pretrained=False, model_dir=modelzoopath, nparts=nparts, num_classes=num_classes, attention=attention_flag, device=device)\n",
        "# model1.load_state_dict(model_state_dict, strict=True)\n",
        "# model1.to(device)\n",
        "\n",
        "\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-5epoch.model'\n",
        "# load_params = torch.load(os.path.join(modelpath, modelname), map_location=device)\n",
        "# networkname = modelname.split('-')[1]\n",
        "# model_state_dict, train_params = load_params['model_params'], load_params['train_params']\n",
        "# model5 = resnet50(pretrained=False, model_dir=modelzoopath, nparts=nparts, num_classes=num_classes, attention=attention_flag, device=device)\n",
        "# model5.load_state_dict(model_state_dict, strict=True)\n",
        "# model5.to(device)\n",
        "\n",
        "\n",
        "# modelname = r'stdogs25-net50-att2-lmgm1-entropy1-soft0.05-lr0.01-imgsz448-bsz16-50epoch.model'\n",
        "# load_params = torch.load(os.path.join(modelpath, modelname), map_location=device)\n",
        "# networkname = modelname.split('-')[1]\n",
        "# model_state_dict, train_params = load_params['model_params'], load_params['train_params']\n",
        "# model50 = resnet50(pretrained=False, model_dir=modelzoopath, nparts=nparts, num_classes=num_classes, attention=attention_flag, device=device)\n",
        "# model50.load_state_dict(model_state_dict, strict=True)\n",
        "# model50.to(device)"
      ],
      "metadata": {
        "id": "GQkJ7mDf8DT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize activation maps"
      ],
      "metadata": {
        "id": "MS53xQ8gMnC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "path1 = '/content/drive/MyDrive/Capstone/stdogs25/Images/n02086646-Blenheim_spaniel/n02086646_602.jpg'\n",
        "path2 = '/content/drive/MyDrive/Capstone/stdogs25/Images/n02099601-golden_retriever/n02099601_304.jpg'\n",
        "path3 = '/content/drive/MyDrive/Capstone/stdogs25/Images/n02110185-Siberian_husky/n02110185_248.jpg'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((448, 448)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "img = Image.open(path3)\n",
        "input = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "xglobal, xlocal, xcosin, xmaps = model5(input)\n",
        "data = xmaps.cpu().numpy()\n",
        "\n",
        "# Get activation maps\n",
        "att1 = data[0, 0, :, :]\n",
        "for i in range(1, 1024):\n",
        "  att1 = np.add(att1, data[0, i, :, :])\n",
        "# att1 = 255 - att1\n",
        "att1 = cv2.resize(att1, (448, 448))\n",
        "\n",
        "att2 = data[0, 1024, :, :]\n",
        "for i in range(1025, 2048):\n",
        "  att2 = np.add(att2, data[0, i, :, :])\n",
        "# att2 = 255 - att2\n",
        "att2 = cv2.resize(att2, (448, 448))\n",
        "\n",
        "# Get input image\n",
        "img = img.resize((448, 448))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "# Plot image\n",
        "ax.imshow(img)\n",
        "# Plot pcolormesh of activation map\n",
        "# p1 = ax.pcolormesh(att1, alpha=0.1)\n",
        "p2 = ax.pcolormesh(att2, alpha=0.1)\n",
        "# fig.colorbar(p2, ax=ax)\n",
        "# plt.savefig(f'husky248_group2_1epoch.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# xglobal, xlocal, xcosin, xmaps = model50(input)\n",
        "# data = xmaps.cpu().numpy()\n",
        "\n",
        "# # Get activation maps\n",
        "# att1 = data[0, 0, :, :]\n",
        "# for i in range(1, 1024):\n",
        "#   att1 = np.add(att1, data[0, i, :, :])\n",
        "# att1 = cv2.resize(att1, (448, 448))\n",
        "\n",
        "# att2 = data[0, 1024, :, :]\n",
        "# for i in range(1025, 2048):\n",
        "#   att2 = np.add(att2, data[0, i, :, :])\n",
        "# att2 = 255 - att2\n",
        "# att2 = cv2.resize(att2, (448, 448))\n",
        "\n",
        "# # Get input image\n",
        "# img = img.resize((448, 448))\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(1)\n",
        "# # Plot image\n",
        "# ax.imshow(img)\n",
        "# # Plot pcolormesh of activation map\n",
        "# # p1 = ax.pcolormesh(att1, alpha=0.1)\n",
        "# p2 = ax.pcolormesh(att2, alpha=0.1)\n",
        "# # fig.colorbar(p2, ax=ax)\n",
        "# # plt.savefig(f'husky248_group2_50epoch.png')"
      ],
      "metadata": {
        "id": "TMxA2sXD1H6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 1024):\n",
        "  # plt.figure(i)\n",
        "  plt.imshow(data[0, i])"
      ],
      "metadata": {
        "id": "sfbtMBY_6JHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xmaps = test_rsltparams['xmaps']\n",
        "x = xmaps.view(1, 2048, -1)\n",
        "print(x.shape)\n",
        "xl = x.cpu().numpy().squeeze()\n",
        "\n",
        "xcosin = test_rsltparams['xcosin']\n",
        "a = xcosin.cpu().numpy().squeeze()\n",
        "\n",
        "xl_ = np.matmul(a, xl)\n",
        "xl_ = np.reshape(xl_, (2048, 14, 14))\n",
        "print(np.shape(xl_))\n",
        "\n",
        "for i in range(2048):\n",
        "  # plt.figure(i)\n",
        "  plt.imshow(xmaps.cpu().numpy().squeeze()[i])"
      ],
      "metadata": {
        "id": "qDqsmxmv79lU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}