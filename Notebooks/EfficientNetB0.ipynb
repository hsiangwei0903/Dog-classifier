{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB0",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzG43Vg/rVRmfFOVc8qbT/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsiangwei0903/Fine-Grained-Object-Recognition/blob/dev%2Fravi%2Ftent/Notebooks/EfficientNetB0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ravi Sangani**"
      ],
      "metadata": {
        "id": "gbb4FX46vmyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. Unlike conventional practice that arbitrary scales these factors, the EfficientNet scaling method uniformly scales network width, depth, and resolution with a set of fixed scaling coefficients. For example, if we want to use $2^N$ times more computational resources, then we can simply increase the network depth by $\\alpha ^ N$, width by $\\beta ^ N$, and image size by $\\gamma ^ N$, where $\\alpha, \\beta, \\gamma$ are constant coefficients determined by a small grid search on the original small model. EfficientNet uses a compound coefficient $\\phi$ to uniformly scales network width, depth, and resolution in a principled way.\n",
        "\n",
        "The compound scaling method is justified by the intuition that if the input image is bigger, then the network needs more layers to increase the receptive field and more channels to capture more fine-grained patterns on the bigger image.\n",
        "\n",
        "The base EfficientNet-B0 network is based on the inverted bottleneck residual blocks of MobileNetV2, in addition to squeeze-and-excitation blocks."
      ],
      "metadata": {
        "id": "AUxkBhu1NAkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install timm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo6w-pwf5HUK",
        "outputId": "a7787eb2-7aac-49b3-d2f7-28e7d2a620b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02085620-Chihuahua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmyRyMk5X4F",
        "outputId": "70f950fb-bf88-482e-9777-415c03366ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_google/n02085620-Chihuahua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inference on single image**"
      ],
      "metadata": {
        "id": "7ny6QQZSAu5M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DppQPD_d0m7z",
        "outputId": "cba580d2-24e5-4f35-a292-582d97fb720e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): SiLU(inplace=True)\n",
              "  (blocks): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): DepthwiseSeparableConv(\n",
              "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act2): SiLU(inplace=True)\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import timm\n",
        "import time\n",
        "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "# url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "# urllib.request.urlretrieve(url, filename)\n",
        "# img = Image.open(filename).convert('RGB')\n",
        "filename = \"n02085620_0.jpg\"\n",
        "\n",
        "img = Image.open(filename).convert('RGB')\n",
        "read_image = mpimg.imread(filename)\n",
        "implot = plt.imshow(read_image)\n",
        "plt.show()\n",
        "\n",
        "tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "plt.imshow(np.transpose(transform(img)))\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "1UOPWayM6esp",
        "outputId": "fe4d8800-a3a3-4b96-da5d-e52b19b42a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2cdf7d66b0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"n02085620_0.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mread_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'n02085620_0.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "  out = model(tensor)\n",
        "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "print(probabilities.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX8o27za3vsQ",
        "outputId": "37a91382-3e6e-43d1-d356-b2bb5e87fded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "picture_of = \"Italian greyhound\"\n",
        "print([picture_of in categories])\n",
        "# Print top categories per image\n",
        "top10_prob, top10_catid = torch.topk(probabilities, 10)\n",
        "for i in range(top10_prob.size(0)):\n",
        "    print(categories[top10_catid[i]], top10_prob[i].item())"
      ],
      "metadata": {
        "id": "mCK4PKVF6xKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_IMAGES_ENTIRE = 0;\n",
        "TOTAL_CORRECT_ENTIRE = 0;"
      ],
      "metadata": {
        "id": "lUNOJpWVdM_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all ratterrier/chihuahua images**\n",
        "-avg latency is calculated here too\n"
      ],
      "metadata": {
        "id": "vHIj2YAIjfR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02085620-Chihuahua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEpwE9DZxP-l",
        "outputId": "42f633a7-fabd-4eab-9289-6ce1982c7869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02085620-Chihuahua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "latency_sum = 0\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"chihuahua\"\n",
        "key_words = [\"chihuahua\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  latency_s = time.time()\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    latency_curr_time = (time.time() - latency_s) # find latency end\n",
        "    latency_sum += latency_curr_time\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      # print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      # print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      # print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    # else:\n",
        "    #   print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "    #   print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "average_time = (latency_sum)/total_number_of_images\n",
        "print(\"Average latency is \" + str(average_time))\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt7raDQRUc5L",
        "outputId": "426a8d81-f58f-4d99-ff7d-a267a839afbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "chihuahua is a category in ImageNet?: True\n",
            "Total images: 10\n",
            "EfficientNetB0121 had a 60.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02085620-Chihuahua\n",
            "Average latency is 0.41196508407592775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all husky images**"
      ],
      "metadata": {
        "id": "ztTmNNMzw9EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02110185-Siberian_husky"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i2FM81txNZQ",
        "outputId": "1973e3d4-15bb-4e66-d392-72675ecec2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02110185-Siberian_husky\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"siberian husky\"\n",
        "key_words = [\"husky\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8izJk5vZpQ2M",
        "outputId": "195b3e68-f194-472a-9fcc-fde4d8fa6b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "siberian husky is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "siberian husky 0.8132025599479675\n",
            "n02110185_0.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.7214768528938293\n",
            "n02110185_1.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.41881847381591797\n",
            "n02110185_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.35797983407974243\n",
            "n02110185_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "eskimo dog 0.18752485513687134\n",
            "n02110185_4.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.6738320589065552\n",
            "n02110185_5.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "eskimo dog 0.21567073464393616\n",
            "n02110185_6.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "eskimo dog 0.3554164171218872\n",
            "n02110185_7.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.4131791591644287\n",
            "n02110185_8.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "siberian husky 0.36751893162727356\n",
            "n02110185_9.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 10\n",
            "EfficientNetB0121 had a 70.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02110185-Siberian_husky\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all labrador images**"
      ],
      "metadata": {
        "id": "AfC2t3y1BP0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02099712-Labrador_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYM3a4-NA_kJ",
        "outputId": "67acf17c-0f84-45a8-ca18-0793673f73b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02099712-Labrador_retriever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"labrador retriever\"\n",
        "key_words = [\"labrador\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Q6oSmVBjSB",
        "outputId": "c0e41059-898e-40c8-df2c-31fea376c6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "labrador retriever is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "rhodesian ridgeback 0.5315908193588257\n",
            "n02099712_0.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "kuvasz 0.19253641366958618\n",
            "n02099712_1.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "kelpie 0.20498140156269073\n",
            "n02099712_2.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "airedale 0.1534002721309662\n",
            "n02099712_3.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "irish setter 0.40218397974967957\n",
            "n02099712_4.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "golden retriever 0.5995801091194153\n",
            "n02099712_5.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "great pyrenees 0.3682955801486969\n",
            "n02099712_6.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "labrador retriever 0.2340882122516632\n",
            "n02099712_7.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 8\n",
            "EfficientNetB0121 had a 12.5% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02099712-Labrador_retriever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all greyhound images**"
      ],
      "metadata": {
        "id": "y6C-v53rBV1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02091032-Italian_greyhound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElaWLgCNBaZM",
        "outputId": "945ebace-bd10-4983-e16e-5d26669cf354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02091032-Italian_greyhound\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"italian greyhound\"\n",
        "key_words = [\"greyhound\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4-nobagCLKS",
        "outputId": "9a55aaf8-10d1-483b-98b2-e6625ff95445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "italian greyhound is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "italian greyhound 0.732166051864624\n",
            "n02091032_0.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "italian greyhound 0.49038368463516235\n",
            "n02091032_1.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "italian greyhound 0.6394500136375427\n",
            "n02091032_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "italian greyhound 0.3496498465538025\n",
            "n02091032_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "italian greyhound 0.6611074805259705\n",
            "n02091032_4.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "whippet 0.3790211081504822\n",
            "n02091032_5.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "italian greyhound 0.31632018089294434\n",
            "n02091032_6.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 7\n",
            "EfficientNetB0121 had a 85.71428571428571% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02091032-Italian_greyhound\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all german sheperd images**"
      ],
      "metadata": {
        "id": "REG3Rs3nDRKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02106662-German_shepherd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ2LsKHJDXXb",
        "outputId": "763c0d2b-e2e4-438d-9c6e-0f5583fe2b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02106662-German_shepherd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "print(categories)\n",
        "picture_of = \"german shepherd\"\n",
        "key_words = [\"german shepherd\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_39dp_ZDXcJ",
        "outputId": "2a4be400-308a-4e0e-9bff-02cc944093d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'water ouzel', 'kite', 'bald eagle', 'vulture', 'great grey owl', 'european fire salamander', 'common newt', 'eft', 'spotted salamander', 'axolotl', 'bullfrog', 'tree frog', 'tailed frog', 'loggerhead', 'leatherback turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'common iguana', 'american chameleon', 'whiptail', 'agama', 'frilled lizard', 'alligator lizard', 'gila monster', 'green lizard', 'african chameleon', 'komodo dragon', 'african crocodile', 'american alligator', 'triceratops', 'thunder snake', 'ringneck snake', 'hognose snake', 'green snake', 'king snake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'rock python', 'indian cobra', 'green mamba', 'sea snake', 'horned viper', 'diamondback', 'sidewinder', 'trilobite', 'harvestman', 'scorpion', 'black and gold garden spider', 'barn spider', 'garden spider', 'black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie chicken', 'peacock', 'quail', 'partridge', 'african grey', 'macaw', 'sulphur-crested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'drake', 'red-breasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'american egret', 'bittern', 'crane', 'limpkin', 'european gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'red-backed sandpiper', 'redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese spaniel', 'maltese dog', 'pekinese', 'shih-tzu', 'blenheim spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-and-tan coonhound', 'walker hound', 'english foxhound', 'redbone', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bullterrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire-haired fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale', 'cairn', 'australian terrier', 'dandie dinmont', 'boston bull', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scotch terrier', 'tibetan terrier', 'silky terrier', 'soft-coated wheaten terrier', 'west highland white terrier', 'lhasa', 'flat-coated retriever', 'curly-coated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german short-haired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany spaniel', 'clumber', 'english springer', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres', 'rottweiler', 'german shepherd', 'doberman', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller', 'entlebucher', 'boxer', 'bull mastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'saint bernard', 'eskimo dog', 'malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberg', 'newfoundland', 'great pyrenees', 'samoyed', 'pomeranian', 'chow', 'keeshond', 'brabancon griffon', 'pembroke', 'cardigan', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless', 'timber wolf', 'white wolf', 'red wolf', 'coyote', 'dingo', 'dhole', 'african hunting dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian cat', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'ice bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'long-horned beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket', 'walking stick', 'cockroach', 'mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'admiral', 'ringlet', 'monarch', 'cabbage butterfly', 'sulphur butterfly', 'lycaenid', 'starfish', 'sea urchin', 'sea cucumber', 'wood rabbit', 'hare', 'angora', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'sorrel', 'zebra', 'hog', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram', 'bighorn', 'ibex', 'hartebeest', 'impala', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'polecat', 'black-footed ferret', 'otter', 'skunk', 'badger', 'armadillo', 'three-toed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas', 'baboon', 'macaque', 'langur', 'colobus', 'proboscis monkey', 'marmoset', 'capuchin', 'howler monkey', 'titi', 'spider monkey', 'squirrel monkey', 'madagascar cat', 'indri', 'indian elephant', 'african elephant', 'lesser panda', 'giant panda', 'barracouta', 'eel', 'coho', 'rock beauty', 'anemone fish', 'sturgeon', 'gar', 'lionfish', 'puffer', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibian', 'analog clock', 'apiary', 'apron', 'ashcan', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint', 'band aid', 'banjo', 'bannister', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'barrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathing cap', 'bath towel', 'bathtub', 'beach wagon', 'beacon', 'beaker', 'bearskin', 'beer bottle', 'beer glass', 'bell cote', 'bib', 'bicycle-built-for-two', 'bikini', 'binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsled', 'bolo tie', 'bonnet', 'bookcase', 'bookshop', 'bottlecap', 'bow', 'bow tie', 'brass', 'brassiere', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'bullet train', 'butcher shop', 'cab', 'caldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', \"carpenter's kit\", 'carton', 'car wheel', 'cash machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'cellular telephone', 'chain', 'chainlink fence', 'chain mail', 'chain saw', 'chest', 'chiffonier', 'chime', 'china cabinet', 'christmas stocking', 'church', 'cinema', 'cleaver', 'cliff dwelling', 'cloak', 'clog', 'cocktail shaker', 'coffee mug', 'coffeepot', 'coil', 'combination lock', 'computer keyboard', 'confectionery', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'crane', 'crash helmet', 'crate', 'crib', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishrag', 'dishwasher', 'disk brake', 'dock', 'dogsled', 'dome', 'doormat', 'drilling platform', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso maker', 'face powder', 'feather boa', 'file', 'fireboat', 'fire engine', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'four-poster', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gasmask', 'gas pump', 'goblet', 'go-kart', 'golf ball', 'golfcart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'grille', 'grocery store', 'guillotine', 'hair slide', 'hair spray', 'half track', 'hammer', 'hamper', 'hand blower', 'hand-held computer', 'handkerchief', 'hard disc', 'harmonica', 'harp', 'harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal bar', 'horse cart', 'hourglass', 'ipod', 'iron', \"jack-o'-lantern\", 'jean', 'jeep', 'jersey', 'jigsaw puzzle', 'jinrikisha', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'liner', 'lipstick', 'loafer', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'magnetic compass', 'mailbag', 'mailbox', 'maillot', 'maillot', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine chest', 'megalith', 'microphone', 'microwave', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito net', 'motor scooter', 'mountain bike', 'mountain tent', 'mouse', 'mousetrap', 'moving van', 'muzzle', 'nail', 'neck brace', 'necklace', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'organ', 'oscilloscope', 'overskirt', 'oxcart', 'oxygen mask', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'passenger car', 'patio', 'pay-phone', 'pedestal', 'pencil box', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'pick', 'pickelhaube', 'picket fence', 'pickup', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'ping-pong ball', 'pinwheel', 'pirate', 'pitcher', 'plane', 'planetarium', 'plastic bag', 'plate rack', 'plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'pop bottle', 'pot', \"potter's wheel\", 'power drill', 'prayer rug', 'printer', 'prison', 'projectile', 'projector', 'puck', 'punching bag', 'purse', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'rubber eraser', 'rugby ball', 'rule', 'running shoe', 'safe', 'safety pin', 'saltshaker', 'sandal', 'sarong', 'sax', 'scabbard', 'scale', 'school bus', 'schooner', 'scoreboard', 'screen', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe shop', 'shoji', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar dish', 'sombrero', 'soup bowl', 'space bar', 'space heater', 'space shuttle', 'spatula', 'speedboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'steel arch bridge', 'steel drum', 'stethoscope', 'stole', 'stone wall', 'stopwatch', 'stove', 'strainer', 'streetcar', 'stretcher', 'studio couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension bridge', 'swab', 'sweatshirt', 'swimming trunks', 'swing', 'switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy', 'television', 'tennis ball', 'thatch', 'theater curtain', 'thimble', 'thresher', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toyshop', 'tractor', 'trailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'vase', 'vault', 'velvet', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'warplane', 'washbasin', 'washer', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'wing', 'wok', 'wooden spoon', 'wool', 'worm fence', 'wreck', 'yawl', 'yurt', 'web site', 'comic book', 'crossword puzzle', 'street sign', 'traffic light', 'book jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'ice lolly', 'french loaf', 'bagel', 'pretzel', 'cheeseburger', 'hotdog', 'mashed potato', 'head cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate sauce', 'dough', 'meat loaf', 'pizza', 'potpie', 'burrito', 'red wine', 'espresso', 'cup', 'eggnog', 'alp', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeside', 'promontory', 'sandbar', 'seashore', 'valley', 'volcano', 'ballplayer', 'groom', 'scuba diver', 'rapeseed', 'daisy', \"yellow lady's slipper\", 'corn', 'acorn', 'hip', 'buckeye', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn', 'earthstar', 'hen-of-the-woods', 'bolete', 'ear', 'toilet tissue']\n",
            "german shepherd is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "german shepherd 0.8194625377655029\n",
            "n02106662_0.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malinois 0.1685788631439209\n",
            "n02106662_1.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "hog 0.15234044194221497\n",
            "n02106662_2.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "german shepherd 0.9862774014472961\n",
            "n02106662_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "german shepherd 0.7150320410728455\n",
            "n02106662_4.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malinois 0.6150093674659729\n",
            "n02106662_5.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "german shepherd 0.9806415438652039\n",
            "n02106662_6.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malinois 0.18242725729942322\n",
            "n02106662_7.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "television 0.371778279542923\n",
            "n02106662_8.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "german shepherd 0.8917416334152222\n",
            "n02106662_9.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "german shepherd 0.7938148379325867\n",
            "n02106662_10.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 11\n",
            "EfficientNetB0121 had a 54.54545454545454% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02106662-German_shepherd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **running inferences on all malamute images**"
      ],
      "metadata": {
        "id": "f1B3H3BXEt3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02110063-malamute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZa5rCKCE1NF",
        "outputId": "50f523fa-1ca9-473a-dd53-7ede310ce05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02110063-malamute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"malamute\"\n",
        "key_words = [\"malamute\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv6qVmEXE60q",
        "outputId": "03c767b6-d74c-42cd-b951-37a0a4211f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "malamute is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "malamute 0.8728640079498291\n",
            "n02110063_0.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "eskimo dog 0.36664658784866333\n",
            "n02110063_1.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malamute 0.5233763456344604\n",
            "n02110063_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malamute 0.42292413115501404\n",
            "n02110063_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "keeshond 0.15274477005004883\n",
            "n02110063_4.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malamute 0.536411464214325\n",
            "n02110063_5.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malamute 0.3682514429092407\n",
            "n02110063_6.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "malamute 0.6635617017745972\n",
            "n02110063_7.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 8\n",
            "EfficientNetB0121 had a 75.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02110063-malamute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### notes"
      ],
      "metadata": {
        "id": "qShw8YmWG4ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://imagesvc.meredithcorp.io/v3/mm/image?url=https%3A%2F%2Fstatic.onecms.io%2Fwp-content%2Fuploads%2Fsites%2F47%2F2021%2F08%2F10%2Falaskan-malamute-vs-siberian-husky-infographic.png\n",
        ")\n",
        "\n",
        "interesting results, the siberian husky is almost identical to malamute\n"
      ],
      "metadata": {
        "id": "4ZE9Bo4CFOCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## running inference on all miniature schnauzer images\n",
        "-avg throughput per 1 min is also calculated here"
      ],
      "metadata": {
        "id": "AlKG5s9vCWcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02097047-miniature_schnauzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e0ijLIACjcW",
        "outputId": "5f0e8d73-73e5-4942-9a39-2a3afd7c1706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02097047-miniature_schnauzer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"miniature schnauzer\"\n",
        "key_words = [\"miniature schnauzer\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "beginning_time = time.time()\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      # print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      # print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      # print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    # else:\n",
        "    #   print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "    #   print(\"\\n\")\n",
        "ending_time = time.time()\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "print(str(total_number_of_images) + \" took this long: \" + str(ending_time - beginning_time))\n",
        "minute_throughput = (60 * total_number_of_images) / (ending_time - beginning_time)\n",
        "print (\"Minute throughpout: \" + str(minute_throughput))\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SErvm3YLCrOS",
        "outputId": "ebfcf9a6-7b1b-41cd-ab6a-a7998472b728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "miniature schnauzer is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "Total images: 10\n",
            "EfficientNetB0121 had a 20.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02097047-miniature_schnauzer\n",
            "10 took this long: 4.010533094406128\n",
            "Minute throughpout: 149.6060463475235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## running inference on all Doberman images"
      ],
      "metadata": {
        "id": "tG-0LuctFZQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02107142-Doberman"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kQ3NrVJQlAd",
        "outputId": "a7d6e4e4-6e32-4e24-fc27-34fa7f06a9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02107142-Doberman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"doberman\"\n",
        "key_words = [\"doberman\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHMHwsN5Qluz",
        "outputId": "178738c4-a672-4397-9cf2-e04f5422865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "doberman is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "doberman 0.5514718294143677\n",
            "n02107142_0.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.14994113147258759\n",
            "n02107142_1.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.9583460688591003\n",
            "n02107142_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.8576943278312683\n",
            "n02107142_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.5287362337112427\n",
            "n02107142_4.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "vizsla 0.3547234833240509\n",
            "n02107142_5.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.5537109971046448\n",
            "n02107142_6.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.5032423734664917\n",
            "n02107142_7.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.35859593749046326\n",
            "n02107142_8.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "doberman 0.5955802798271179\n",
            "n02107142_9.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 10\n",
            "EfficientNetB0121 had a 90.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02107142-Doberman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## running inference on all american staffordshire terrier images"
      ],
      "metadata": {
        "id": "I5lSUhrOJXOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02093428-American_Staffordshire_terrier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJhKjFt8RK2k",
        "outputId": "303ce4ac-1a29-41b3-edf2-63b9b65bee2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02093428-American_Staffordshire_terrier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"terrier\"\n",
        "key_words = [\"terrier\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXiNg4uMRNCP",
        "outputId": "7d2deadd-49e3-42c4-a4a1-057d308cfebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "terrier is a category in ImageNet?: False\n",
            "\n",
            "\n",
            "chihuahua 0.5648274421691895\n",
            "n02093428_0.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "staffordshire bullterrier 0.5088037252426147\n",
            "n02093428_1.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "american staffordshire terrier 0.433464914560318\n",
            "n02093428_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "american staffordshire terrier 0.9101479649543762\n",
            "n02093428_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 4\n",
            "EfficientNetB0121 had a 75.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02093428-American_Staffordshire_terrier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## running inference on all standard poodle images"
      ],
      "metadata": {
        "id": "gnZb_c8ie_6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/UW/2021-22_Senior/Capstone/ENGINE: Wyze/Images/test_yt/n02113799-standard_poodle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o52BvXhfK31",
        "outputId": "0c021359-bc1f-4aee-ff0e-40805a4ea4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02113799-standard_poodle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "print(config)\n",
        "\n",
        "accurate_prediction_counter = 0\n",
        "total_number_of_images = 0\n",
        "\n",
        "# Get imagenet class mappings\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "categories = [category.lower() for category in categories]\n",
        "picture_of = \"standard poodle\"\n",
        "key_words = [\"poodle\"]\n",
        "softmax_accuracy_threshold = 0.0\n",
        "contains = (picture_of in categories)\n",
        "print(picture_of + \" is a category in ImageNet?: \" + str(contains))\n",
        "print(\"\\n\")\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    total_number_of_images += 1\n",
        "    img = Image.open(filename).convert('RGB')\n",
        "    tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
        "    with torch.no_grad():\n",
        "      out = model(tensor)\n",
        "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "    accurate_prediction = False\n",
        "    # Print top categories per image\n",
        "    top3_prob, top3_catid = torch.topk(probabilities, 1)\n",
        "    for i in range(top3_prob.size(0)):\n",
        "      print(categories[top3_catid[i]], top3_prob[i].item())\n",
        "      category = categories[top3_catid[i]]\n",
        "      for key_word in key_words:\n",
        "        if (key_word in category) and (top3_prob[i].item() > softmax_accuracy_threshold):\n",
        "          accurate_prediction = True\n",
        "    if (accurate_prediction):\n",
        "      print(filename + \" had its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "      accurate_prediction_counter += 1\n",
        "    else:\n",
        "      print(filename + \" did not have its actual category in the top 1 prediction with softmax > \" + str(softmax_accuracy_threshold))\n",
        "      print(\"\\n\")\n",
        "accuracy = (accurate_prediction_counter / total_number_of_images) * 100\n",
        "print(\"Total images: \" + str(total_number_of_images))\n",
        "print(\"EfficientNetB0121 had a \" + str(accuracy) + \"% accuracy on images in \" + os.getcwd())\n",
        "TOTAL_IMAGES_ENTIRE += total_number_of_images\n",
        "TOTAL_CORRECT_ENTIRE += accurate_prediction_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2a-f1EgfIQy",
        "outputId": "f94330bd-553f-40fa-fe1d-440b9b66e95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}\n",
            "standard poodle is a category in ImageNet?: True\n",
            "\n",
            "\n",
            "chow 0.343498557806015\n",
            "n02113799_0.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "hyena 0.3403847813606262\n",
            "n02113799_1.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "toy poodle 0.3280598819255829\n",
            "n02113799_2.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "standard poodle 0.42763248085975647\n",
            "n02113799_3.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "irish water spaniel 0.5190920829772949\n",
            "n02113799_4.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "standard poodle 0.2253575325012207\n",
            "n02113799_5.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "standard poodle 0.8908197283744812\n",
            "n02113799_6.jpg had its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "chesapeake bay retriever 0.0840025246143341\n",
            "n02113799_7.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "curly-coated retriever 0.25131016969680786\n",
            "n02113799_8.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "ox 0.21108058094978333\n",
            "n02113799_9.jpg did not have its actual category in the top 1 prediction with softmax > 0.0\n",
            "\n",
            "\n",
            "Total images: 10\n",
            "EfficientNetB0121 had a 40.0% accuracy on images in /content/drive/.shortcut-targets-by-id/1beXLuTyfFnOo3t19p65wHXF-qaxghvjI/ENGINE: Wyze/Images/test_yt/n02113799-standard_poodle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"accuracy is \" + str(TOTAL_CORRECT_ENTIRE/TOTAL_IMAGES_ENTIRE))\n",
        "print(\"latency is: \" + str(average_time))\n",
        "print(\"throughput per 60s is \" + str(minute_throughput))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvPDJ7E1di-F",
        "outputId": "e266f947-d3f9-4271-968f-ddac45a05962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.5681818181818182\n",
            "latency is: 0.41196508407592775\n",
            "throughput per 60s is 149.6060463475235\n"
          ]
        }
      ]
    }
  ]
}