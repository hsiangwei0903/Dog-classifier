{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Pretrained MobileNetV2</h1>\n",
        "<p>Additional documentation for pretrained model model can be found at <a href=https://github.com/rwightman/pytorch-image-models/blob/master/docs/models/mobilenet-v2.md>https://github.com/rwightman/pytorch-image-models/blob/master/docs/models/mobilenet-v2.md</a>.</p>"
      ],
      "metadata": {
        "id": "GS1BavJG4_Od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>System Setup</h2>\n",
        "<p>Run the follwing command in terminal to install the deep learning library:</p>"
      ],
      "metadata": {
        "id": "DnH_c-h_5MRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "rVeXNSQtwQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Import Statements + Model Instantiation</h2>"
      ],
      "metadata": {
        "id": "_2KZ_pkS5pPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Timing\n",
        "import time\n",
        "\n",
        "# Model\n",
        "import timm\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
        "from gc import enable\n",
        "\n",
        "# Image Processing\n",
        "import urllib\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform"
      ],
      "metadata": {
        "id": "2VLK0V-95zMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicate device and model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "m = timm.create_model('mobilenetv2_050', pretrained=True)\n",
        "\n",
        "# Set model into evaluation mode\n",
        "m.eval()"
      ],
      "metadata": {
        "id": "UaLX_W6uk1MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Load + Preprocessing for a Single Image</h2>\n",
        "<p>The prepocessing performs a random 224x224 crop because the test image should be unpredictable.</p>"
      ],
      "metadata": {
        "id": "wm9Tgb3U7u7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = resolve_data_config({}, model=m)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "# If fetching the test image from a url, use the format below:\n",
        "# url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "# urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Otherwise, mount Google drive to notebook and open image as a file:\n",
        "img_path = '/content/drive/MyDrive/ENGINE: Wyze/Images/test/n02093428-American_Staffordshire_terrier/n02093428_0.jpg';\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "# Randomly crop the image to 224x224\n",
        "tfm = RandomResizedCropAndInterpolation(size=224)\n",
        "random = tfm(img)\n",
        "plt.imshow(random)\n",
        "\n",
        "tensor = transform(img).unsqueeze(0) # transform and add batch dimension"
      ],
      "metadata": {
        "id": "U8GiefaOjqb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Helper Function Definition</h2>\n",
        "<ul><li>accuracy() : find the accuracy of the model for a single image. The function also incorporates timing evaluation calls.</li>"
      ],
      "metadata": {
        "id": "Cxoe8WHv881N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(img_path):\n",
        "  img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "  # Randomly select a 512x512 frame\n",
        "  tfm = RandomResizedCropAndInterpolation(size=512)\n",
        "  random_crop = tfm(img)\n",
        " \n",
        "  # Transform and add batch dimension\n",
        "  tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "  # Start timer to calculate latency and make prediction w model\n",
        "  latency_s = time.time()\n",
        "  with torch.no_grad():\n",
        "    out = m(tensor)\n",
        "  latency = (time.time()-latency_s)*1000\n",
        " \n",
        "\n",
        "  # Probabilities for each breed\n",
        "  probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "\n",
        "  # Grab breeds classes\n",
        "  url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "  urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "  with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "  # Get top 1 for the image\n",
        "  #   -top1_prob[0].item() is the probability\n",
        "  #   -categories[top1_catid[i]] is the label\n",
        "  top1_prob, top1_catid = torch.topk(probabilities, 1)\n",
        "\n",
        "  confidence = top1_prob[0].item()\n",
        "  label = categories[top1_catid[0]]\n",
        "  return confidence, label, latency"
      ],
      "metadata": {
        "id": "b9y9wOMjU2go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Main() to Find Accuracy of Small Test Dataset</h2>\n",
        "<p>For each image, the function will print out the predicted breed alongside the confidence. To find accuracy, manually confirm that the predicted breed matches the image class and evaluate (# of correct predictions/total # of images).</p>"
      ],
      "metadata": {
        "id": "mHnydJX1_kxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Path to folders containing dog images\n",
        "  folders = ['/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02085620-Chihuahua',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02091032-Italian_greyhound',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02093428-American_Staffordshire_terrier',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02097047-miniature_schnauzer',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02099712-Labrador_retriever',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02106662-German_shepherd',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02107142-Doberman',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02110063-malamute',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02110185-Siberian_husky',\n",
        "  '/content/drive/MyDrive/ENGINE: Wyze/Images/test_yt/n02113799-standard_poodle']\n",
        "\n",
        "  # Size and label of each folder respectively\n",
        "  size = [10, 7, 4, 10, 8, 11, 10, 8, 10, 10]\n",
        "  labels = ['n02085620', 'n02091032', 'n02093428', 'n02097047', 'n02099712',\n",
        "            'n02106662', 'n02107142', 'n02110063', 'n02110185', 'n02113799']\n",
        "\n",
        "  # Ongoing sum of total images and total latency\n",
        "  total_img = 0\n",
        "  total_l = 0\n",
        "\n",
        "  # Loop through directory\n",
        "  for i in range(len(size)):\n",
        "    curr_dir = folders[i]\n",
        "    dir_size = size[i]\n",
        "    print(curr_dir)\n",
        "\n",
        "    # Loop through each file in a folder\n",
        "    for j in range(dir_size):\n",
        "      img_path = curr_dir + '/' + labels[i] + '_' + str(j) + '.jpg'\n",
        "      print(img_path)\n",
        "      confidence, label, latency = accuracy(img_path)\n",
        "      total_l += latency\n",
        "      print('    ' + label + '    ' + str(confidence))\n",
        "      total_img += 1\n",
        "\n",
        "  print(total_l/total_img)\n",
        "  print()\n",
        "  print(total_img)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "tMRUo1sNXqru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
